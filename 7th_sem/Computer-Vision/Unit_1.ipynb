{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06fd109",
   "metadata": {},
   "source": [
    "# **UNIT 1: Introduction to Digital Image Processing**\n",
    "\n",
    "* Origins of Digital Image Processing\n",
    "* Elements of Visual Perception\n",
    "* Image Sensing and Acquisition\n",
    "* Image Sampling and Quantization\n",
    "* Relationships Between Pixels\n",
    "\n",
    "**Intensity Transformation and Spatial Filtering:**\n",
    "\n",
    "* Image Negation\n",
    "* Log Transformations\n",
    "* Power Law Transformation\n",
    "* Smoothing Spatial Filters\n",
    "* Sharpening Spatial Filters\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c021bc46",
   "metadata": {},
   "source": [
    "\n",
    "# UNIT 1: Introduction to Digital Image Processing (DIP)\n",
    "\n",
    "Digital Image Processing is the method of taking an image, converting it into numerical form, and then applying different techniques to improve it, analyze it, or extract useful information from it.\n",
    "\n",
    "In simple words, it means:\n",
    "\n",
    "You take an image\n",
    "‚Üí treat it as a collection of tiny pixels\n",
    "‚Üí use computer algorithms to clean it, enhance it, detect patterns, or understand what‚Äôs inside.\n",
    "\n",
    "Some common things done using DIP:\n",
    "\n",
    "‚Ä¢ Removing noise from images  \n",
    "‚Ä¢ Increasing brightness or contrast  \n",
    "‚Ä¢ Detecting edges, shapes, faces, objects  \n",
    "‚Ä¢ Converting colored images to grayscale  \n",
    "‚Ä¢ Medical image analysis (MRI, CT, X-ray)  \n",
    "‚Ä¢ Satellite image processing  \n",
    "‚Ä¢ Pattern recognition\n",
    "\n",
    "DIP is widely used in AI, robotics, medical imaging, surveillance, photography, and many more fields.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Origins of Digital Image Processing**\n",
    "\n",
    "* **Image Processing** started long before computers ‚Äî with **photography, printing, medical imaging**.\n",
    "* **Analogue image processing**: Done using photographs, printing plates, films (not computers). Example: adjusting brightness in old photos during printing.\n",
    "* **Digital image processing (DIP)**: Began in the **1960s** with computers and satellites.\n",
    "\n",
    "  * NASA used DIP to improve **moon & space images** (remove noise, enhance details).\n",
    "  * Medical field: CT scans, MRI images required digital enhancement.\n",
    "  * Defense: Aerial and satellite images for surveillance.\n",
    "* Today: DIP is used in **mobile cameras, biometrics (face/fingerprint scan), social media filters, computer vision, AI, robotics**.\n",
    "\n",
    "üëâ **Summary:** Origins lie in analog photography, but true growth came with computers (1960s onwards), and now DIP is everywhere.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Elements of Visual Perception**\n",
    "\n",
    "This explains how **our eyes & brain** see and interpret images, since DIP tries to mimic human vision.\n",
    "\n",
    "* **Human Eye as a Camera:**\n",
    "\n",
    "  * **Lens** ‚Üí focuses light.\n",
    "  * **Retina** ‚Üí contains light-sensitive cells.\n",
    "  * **Rods** ‚Üí sense **brightness** (work in low light, black & white vision).\n",
    "  * **Cones** ‚Üí sense **color** (red, green, blue).\n",
    "* **Brightness & Contrast:**\n",
    "\n",
    "  * Our eyes detect **differences in intensity** (contrast).\n",
    "  * If two objects have similar brightness ‚Üí hard to distinguish.\n",
    "* **Adaptation:** Eye can adjust between dark and bright environments (dynamic range).\n",
    "* **Perception of Color:** Brain combines RGB signals to create full color images.\n",
    "\n",
    "üëâ **Summary:** DIP systems must consider human vision ‚Äî brightness, contrast, resolution, color ‚Äî to create images that look ‚Äúnatural‚Äù to us.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Image Sensing and Acquisition**\n",
    "\n",
    "How a digital image is formed and captured.\n",
    "\n",
    "* **Image Formation:**\n",
    "\n",
    "  1. A **scene/object** reflects light.\n",
    "  2. A **sensor** (camera, scanner, satellite sensor) captures light.\n",
    "  3. Light is converted to **electrical signals**.\n",
    "  4. Computer converts signals into a **digital image (pixels)**.\n",
    "\n",
    "* **Types of Sensors:**\n",
    "\n",
    "  * **Single Sensor** (like mobile camera).\n",
    "  * **Line Sensor** (1D array, used in scanners).\n",
    "  * **Array Sensors** (2D grids, used in cameras, satellites).\n",
    "\n",
    "* **Acquisition:**\n",
    "\n",
    "  * Capturing ‚Üí Digitizing (sampling + quantization) ‚Üí Storing ‚Üí Processing.\n",
    "\n",
    "üëâ **Summary:** Image acquisition = capturing an image (through sensors) and converting it into a digital form for processing.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Image Sampling and Quantization**\n",
    "\n",
    "This is how we convert a **continuous real-world image** into a **digital image**.\n",
    "\n",
    "* **Sampling:**\n",
    "\n",
    "  * Breaking an image into small dots called **pixels (picture elements)**.\n",
    "  * Decides **spatial resolution** (clarity of details).\n",
    "  * More pixels = higher resolution = clearer image.\n",
    "\n",
    "* **Quantization:**\n",
    "\n",
    "  * Assigning intensity (brightness) values to each pixel.\n",
    "  * Example:\n",
    "\n",
    "    * **1-bit** ‚Üí 2 levels (black & white).\n",
    "    * **8-bit** ‚Üí 256 levels (grayscale).\n",
    "    * **24-bit** ‚Üí 16 million colors (true color).\n",
    "\n",
    "üëâ **Summary:** Sampling = how many pixels, Quantization = how many brightness/color levels. Together they make a continuous image digital.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Relationships Between Pixels**\n",
    "\n",
    "Pixels are the building blocks of an image. Their relationships help in **edge detection, segmentation, filtering, etc.**\n",
    "\n",
    "* **Types of Relationships:**\n",
    "\n",
    "  1. **Neighborhood:**\n",
    "\n",
    "     * **4-neighbors** (up, down, left, right).\n",
    "     * **8-neighbors** (diagonal included).\n",
    "  2. **Connectivity:**\n",
    "\n",
    "     * Defines whether pixels belong to the same region/object.\n",
    "     * 4-connectivity, 8-connectivity, m-connectivity (mix).\n",
    "  3. **Adjacency:**\n",
    "\n",
    "     * Two pixels are adjacent if they are neighbors and have similar intensity.\n",
    "  4. **Distance Measures:**\n",
    "\n",
    "     * **Euclidean distance**: straight-line distance.\n",
    "     * **Manhattan (city-block) distance**: horizontal/vertical moves only.\n",
    "     * **Chessboard distance**: includes diagonals.\n",
    "\n",
    "üëâ **Summary:** Pixel relationships decide how we group pixels together into edges, shapes, and objects.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ Quick Recap (Memory Tips)\n",
    "\n",
    "* **Origins** ‚Üí Space, medical, defense ‚Üí now everywhere.\n",
    "* **Visual Perception** ‚Üí Eye = camera (rods = brightness, cones = color).\n",
    "* **Sensing/Acquisition** ‚Üí Capture + digitize (sensors).\n",
    "* **Sampling** ‚Üí Pixels count (resolution).\n",
    "* **Quantization** ‚Üí Intensity levels (grayscale/colors).\n",
    "* **Pixel Relations** ‚Üí Neighbors, connectivity, distance (important for filters & segmentation).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73289269",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ‚úÖ **Intensity Transformation and Spatial Filtering**\n",
    "\n",
    "Digital Image Processing often changes **pixel intensities** or uses **filters** to improve/enhance images.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Image Negation**\n",
    "\n",
    "* Formula:\n",
    "  $s = L - 1 - r$\n",
    "  where:\n",
    "\n",
    "  * $r$ = input pixel value\n",
    "  * $s$ = output pixel value\n",
    "  * $L$ = maximum gray level (e.g., 256 for 8-bit image).\n",
    "\n",
    "* Meaning: Converts **bright areas ‚Üí dark** and **dark areas ‚Üí bright**.\n",
    "\n",
    "* Example: If $r=50$, $L=256$, then $s=205$.\n",
    "\n",
    "* Uses:\n",
    "\n",
    "  * Enhancing **white/black details**.\n",
    "  * Medical imaging (X-rays, CT scans) ‚Üí makes hidden details more visible.\n",
    "\n",
    "üëâ **Think of it like a photo negative.**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Log Transformation**\n",
    "\n",
    "* Formula:\n",
    "  $s = c \\cdot \\log(1 + r)$\n",
    "  where $c$ is a scaling constant.\n",
    "\n",
    "* Meaning:\n",
    "\n",
    "  * Expands **dark pixel values** (makes details in dark regions visible).\n",
    "  * Compresses **bright pixel values** (reduces intensity of very bright areas).\n",
    "\n",
    "* Uses:\n",
    "\n",
    "  * Useful when image has **huge variation** in brightness.\n",
    "  * Satellite images, medical imaging, photography.\n",
    "\n",
    "üëâ **Think of it as: bring hidden details out of the shadows.**\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Power-Law (Gamma) Transformation**\n",
    "\n",
    "* Formula:\n",
    "  $s = c \\cdot r^{\\gamma}$\n",
    "\n",
    "* Meaning:\n",
    "\n",
    "  * Adjusts overall **brightness and contrast**.\n",
    "  * $\\gamma < 1$ ‚Üí brightens the image.\n",
    "  * $\\gamma > 1$ ‚Üí darkens the image.\n",
    "\n",
    "* Example:\n",
    "\n",
    "  * Phone screen ‚Äúgamma correction‚Äù uses this.\n",
    "  * $\\gamma = 0.5$ ‚Üí boosts dark areas.\n",
    "  * $\\gamma = 2$ ‚Üí suppresses brightness.\n",
    "\n",
    "* Uses:\n",
    "\n",
    "  * Display devices (TV, monitors, mobile screens).\n",
    "  * Pre-processing for computer vision tasks.\n",
    "\n",
    "üëâ **Think of it like a brightness controller knob.**\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Smoothing Spatial Filters (Low-pass filters)**\n",
    "\n",
    "* Goal: **Reduce noise** and **blur image** (remove fine details).\n",
    "* Technique: Replace pixel value with **average of neighbors**.\n",
    "\n",
    "### (a) Mean Filter\n",
    "\n",
    "* Each pixel = average of its surrounding pixels.\n",
    "* Removes random noise but blurs edges.\n",
    "\n",
    "### (b) Weighted Average Filter\n",
    "\n",
    "* Nearby pixels get **more weight** than distant ones.\n",
    "* Blurs less than mean filter.\n",
    "\n",
    "üëâ **Think of it as softening an image to hide unwanted spots.**\n",
    "\n",
    "* Uses:\n",
    "\n",
    "  * Noise reduction in old photos.\n",
    "  * Pre-processing for edge detection.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Sharpening Spatial Filters (High-pass filters)**\n",
    "\n",
    "* Goal: **Highlight edges, fine details, and boundaries.**\n",
    "* Technique: Emphasizes changes in intensity.\n",
    "\n",
    "### (a) Laplacian Filter\n",
    "\n",
    "* Uses second derivative to detect rapid intensity changes.\n",
    "* Highlights edges in all directions.\n",
    "\n",
    "### (b) Sobel / Prewitt Filters\n",
    "\n",
    "* Uses first derivative (gradient) to detect edges.\n",
    "* Detects vertical, horizontal, or diagonal edges.\n",
    "\n",
    "üëâ **Think of it as making the image look ‚Äúsharper‚Äù or more ‚Äúdetailed.‚Äù**\n",
    "\n",
    "* Uses:\n",
    "\n",
    "  * Object detection.\n",
    "  * Medical images (highlighting tumors, bones).\n",
    "  * Satellite images (highlighting roads, rivers).\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ Quick Recap\n",
    "\n",
    "* **Image Negation** ‚Üí Inverts brightness (good for medical/hidden details).\n",
    "* **Log Transformation** ‚Üí Enhances dark details, compresses bright.\n",
    "* **Power Law (Gamma)** ‚Üí Adjusts brightness/contrast (like a knob).\n",
    "* **Smoothing Filters** ‚Üí Blur/reduce noise (average neighbors).\n",
    "* **Sharpening Filters** ‚Üí Enhance edges/details (Laplacian, Sobel).\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
